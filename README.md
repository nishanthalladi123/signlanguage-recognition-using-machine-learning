# ğŸ¤Ÿ Sign Language Recognition using Machine Learning

This project focuses on recognizing American Sign Language (ASL) gestures using a machine learning model trained on image data. The goal is to translate sign gestures into alphabetic text, bridging communication gaps for the hearing-impaired.

---

## ğŸ“Œ Features

- Image classification using ML algorithms
- Preprocessing and feature extraction from sign language images
- Model training and evaluation
- Real-time prediction-ready architecture (future enhancement)

---

## ğŸ› ï¸ Tech Stack

- Python
- NumPy, Pandas
- OpenCV
- Scikit-learn
- Matplotlib & Seaborn

---

## ğŸ§  Model Overview

- Dataset: ASL Alphabet Dataset (26 classes, Aâ€“Z)
- Preprocessing: Grayscale conversion, resizing, noise removal
- Algorithm: Supervised learning using Scikit-learn models (e.g., SVM, RandomForest)
- Evaluation: Accuracy score, confusion matrix

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/nishanthalladi123/signlanguage-recognition-using-machine-learning.git
cd signlanguage-recognition-using-machine-learning
